{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm as tqdm\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "from torchvision.transforms import transforms\n",
    "import pathlib\n",
    "import nibabel as nib\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pathlib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22836\\1560940723.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mmouse\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"M03\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"M04\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"M05\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"M06\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"M07\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"M08\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pathlib' is not defined"
     ]
    }
   ],
   "source": [
    "Train_voor = []\n",
    "\n",
    "Train_na = []\n",
    "\n",
    "\n",
    "\n",
    "path = pathlib.Path(__file__).parent\n",
    "\n",
    "for mouse in [\"M03\", \"M04\", \"M05\", \"M06\", \"M07\", \"M08\"]:\n",
    "\n",
    "    for timestamp in [\"-001h\", \"024h\"]:\n",
    "\n",
    "        if timestamp == \"-001h\":\n",
    "\n",
    "            path_ct = path / f\"processed/{mouse}_{timestamp}_CT280.img\"\n",
    "\n",
    "            Train_voor.append(nib.load(path_ct).get_fdata())\n",
    "\n",
    "        else:\n",
    "\n",
    "            path_ct = path / f\"processed/{mouse}_{timestamp}_CT280.img\"\n",
    "\n",
    "            Train_na.append(nib.load(path_ct).get_fdata())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv_block(nn.Module): #dit is 1 blok van 2 convs gevolgd door een relu\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels) #is dit noodzakelijk en waarom doet men dit?\n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.relu = nn.ReLU() #evt leaky ReLu??\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class encoder_block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = conv_block(in_channels, out_channels)\n",
    "        self.pool = nn.MaxPool2d((2, 2))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.conv(inputs)\n",
    "        p = self.pool(x)\n",
    "\n",
    "        return x, p\n",
    "\n",
    "class decoder_block(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "\n",
    "        self.up = nn.ConvTranspose2d(in_c, out_c, kernel_size=2, stride=2, padding=0)\n",
    "        self.conv = conv_block(out_c+out_c, out_c)\n",
    "\n",
    "    def forward(self, inputs, skip):\n",
    "        x = self.up(inputs)\n",
    "        x = torch.cat([x, skip], axis=1)\n",
    "        x = self.conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() #residuals nog implementeren.\n",
    "\n",
    "        \"\"\" Encoder \"\"\"\n",
    "        self.e1 = encoder_block(1, 64)\n",
    "        self.e2 = encoder_block(64, 128)\n",
    "        self.e3 = encoder_block(128, 256)\n",
    "        self.e4 = encoder_block(256, 512)\n",
    "\n",
    "        \"\"\" Bottleneck \"\"\"\n",
    "        self.b = conv_block(512, 1024) #hoe beslis je eig hoeveel features je wilt per layer?\n",
    "\n",
    "        \"\"\" Decoder \"\"\"\n",
    "        self.d1 = decoder_block(1024, 512)\n",
    "        self.d2 = decoder_block(512, 256)\n",
    "        self.d3 = decoder_block(256, 128)\n",
    "        self.d4 = decoder_block(128, 64)\n",
    "\n",
    "        \"\"\" Classifier \"\"\"\n",
    "        self.outputs = nn.Conv2d(64, 1, kernel_size=1, padding=0)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\" Encoder \"\"\"\n",
    "        s1, p1 = self.e1(inputs)\n",
    "        s2, p2 = self.e2(p1)\n",
    "        s3, p3 = self.e3(p2)\n",
    "        s4, p4 = self.e4(p3)\n",
    "\n",
    "        \"\"\" Bottleneck \"\"\"\n",
    "        b = self.b(p4)\n",
    "\n",
    "        \"\"\" Decoder \"\"\"\n",
    "        d1 = self.d1(b, s4)\n",
    "        d2 = self.d2(d1, s3)\n",
    "        d3 = self.d3(d2, s2)\n",
    "        d4 = self.d4(d3, s1)\n",
    "\n",
    "        outputs = self.outputs(d4)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet().to(device)\n",
    "optimizer = Adam(model.parameters(),lr=0.01,weight_decay=0.001)\n",
    "loss_function = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 15\n",
    "# 6 muizen, 2 time instances, 154 slices, (242,121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = transforms.Compose([transforms.ToTensor(),transforms.Normalize(0.5,0.5)]) #is horizontal flip nodig ?\n",
    "class MuizenDataset(Dataset):\n",
    "\n",
    "    def __init__(self,data_voor,data_na):\n",
    "        super().__init__()\n",
    "        self.data = data #vanwege de kleine dataset laden we het gewoon helemaal in memory\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        input = self.data_voor[index]\n",
    "        target = self.data_na[index]\n",
    "        input = torch.tensor(input)\n",
    "        target = torch.tensor(target)\n",
    "        return input, target\n",
    "\n",
    "train_loader = DataLoader(MuizenDataset(train_data,transform=transformer),batch_size=50,shuffle=True)\n",
    "test_loader = DataLoader(MuizenDataset(test_data,transform=transformer),batch_size=50,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRAINING\n",
    "for epoch in tqdm(range(num_epochs)):  #we itereren meerdere malen over de data tot convergence?\n",
    "    model.train()\n",
    "\n",
    "    for i, (image1,image2) in enumerate(train_loader): #wat is een handige manier om dit in te lezen?\n",
    "        if torch.cuda.is_available():\n",
    "            image_voor=Variable(image1.cuda())\n",
    "            image_na=Variable(image2.cuda())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        image_na_pred = model(image_voor)\n",
    "        loss = loss_function(image_na_pred,image_na) #vergelijk predicted na image met de echte na image\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i%100==0:\n",
    "            print('Step: '+ str(i)+'loss: '+str(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TESTING\n",
    "model.eval()\n",
    "test_acc = []\n",
    "for i, (image1,image2) in enumerate(train_loader): #wat is een handige manier om dit in te lezen?\n",
    "    if torch.cuda.is_available():\n",
    "        image_voor=Variable(image1.cuda())\n",
    "        image_na=Variable(image2.cuda())\n",
    "\n",
    "    image_na_pred = model(image_voor)\n",
    "    loss = loss_function(image_na_pred,image_na) #vergelijk predicted na image met de echte na image\n",
    "    test_acc.append(loss)\n",
    "    if i%100==0:\n",
    "        print('Step: '+ str(i)+'loss: '+str(loss))\n",
    "av_test_acc = np.mean(np.array(test_acc))\n",
    "print(av_test_acc)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1477f09f345c54836698d61586a11c7930607b6c64dd8e48e86789b527ef112b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 ('VOPENV': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
